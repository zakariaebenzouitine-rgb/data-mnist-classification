# ğŸ§  MNIST Handwritten Digit Classification â€” Convolutional Neural Network

This project implements a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset.  
It demonstrates a complete deep-learning workflow, including data preprocessing, model architecture design, training, evaluation, and visualization.

<p align="center">
  <img src="recognition.gif" alt="Digit Recognition Demo" width="300">
</p>

---

## ğŸ“Œ Project Overview

The goal of this project is to build a CNN capable of recognizing handwritten digits (0â€“9) with high accuracy.  
Using the MNIST dataset (70,000 grayscale images of size 28Ã—28), the model learns to identify patterns in handwritten digits and predict the correct class.

This project showcases:
- ğŸ§¼ Data preprocessing for image-based deep learning  
- ğŸ§© Construction of a simple yet effective CNN  
- ğŸ“‰ Training and validation using best practices  
- ğŸ“ˆ Evaluation on unseen test data  
- âš™ï¸ Understanding parameter counts and convolution operations  

---

## ğŸ—‚ï¸ Repository Structure

.
â”œâ”€â”€ mnist_classification.ipynb # Full training pipeline and analysis
â”œâ”€â”€ recognition.gif # Demo animation
â”œâ”€â”€ README.md # Project documentation
â””â”€â”€ .gitignore

---

## ğŸ“Š Dataset

**MNIST Dataset**  
- 60,000 training images  
- 10,000 test images  
- Grayscale (1 channel), size 28Ã—28  
- Classes: digits 0â€“9 (10-class classification)

Images are normalized to the 0â€“1 range and reshaped to `(28, 28, 1)` to match CNN input requirements.  
Labels are one-hot encoded for multiclass classification.

---

## ğŸ§± Model Architecture

The CNN consists of:

- **Conv2D (8 filters, 4Ã—4, ReLU, padding="same")**  
- **MaxPooling2D (2Ã—2)**  
- **Conv2D (16 filters, 4Ã—4, ReLU)**  
- **MaxPooling2D (2Ã—2)**  
- **Flatten**
- **Dense (10 units, ReLU)**
- **Dense (10 units, Softmax)** â€” classification output layer

**Compilation:**
- Loss: `categorical_crossentropy`
- Optimizer: `adam`
- Metric: `accuracy`

Total parameters: **6,320**

---

## ğŸš€ Training

The model is trained for **5 epochs** with:
- A `validation_split` of 0.3  
- Early stopping to preserve the best model  
- Batch size = 32  

On a typical CPU setup, training completes in under one minute.

---

## ğŸ“ˆ Results

**Validation Accuracy:** ~97%  
**Test Accuracy:** **98.17%**

```python
model.evaluate(X_test, y_test_cat)
# Output:
# [0.0586, 0.9817]
